
#### 결측치 처리

```python
df = pd.get_dummies(df)
df = df.fillna(df.mean())
```
- get_dummies(df) : 카테고리형 범주를 원핫인코딩으로 변환
- pd.fillna(df.mean()): 빈 칸을 평균값으로 채워줌


##### 상관분석
```python
df_corr = df.corr()
df_corr_sort = df_corr.sort_values('SalePrice', ascending=False)
print(df_corr_sort['SalePrice'].head())
```
* df.corr(): 상관분석
* df_corr.sort_values('SalePrice', ascending=False): SalePrice 기준으로 descending 정렬
* df_corr_sort['SalePrice'].head() : SalesPrice 상관관계에서 위에서 5개만 출력

##### pairplot
```python
cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']
sns.pairplot(df[cols])
plt.show()
```
* sns.pairplot(df[cols]): 상관도 그래프

##### model.predict
```python
history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])

real_prices = []
pred_prices = []
X_num = []

n_iter = 0
tmp = model.predict(X_test)
print(tmp.shape) # 차원확인
print(tmp.ndim) # 차원 확인
Y_prediction = model.predict(X_test).flatten()
for i in range(25):
    real = y_test[i]
    prediction = Y_prediction[i]
    print("실제가격: {:.2f}, 예상가격: {:.2f}".format(real, prediction))
    real_prices.append(real)

	pred_prices.append(prediction)
	n_iter = n_iter + 1
	X_num.append(n_iter)
```

- model.predict(X_test).flatten()은 1차원 벡터로 평탄화 시키는 것
- tmp는 (292,1)라서 2차원 행렬이고 Y_prediction은 (292, )라서 1차원 벡터
- 디버깅 안할 때 차원 확인은 tmp.shape 혹은 tmp.ndim으로 확인 가능


#### Pytorch

```python
my_tensor = torch.tensor([[1., -1.], [1., -1.]])
```

- 연산 그래프: 방향성이 있으며 변수를 의미하는 **노드**와 연산을 담당하는 **엣지**로 구성

#### 파이토치 특징
- 아키텍처는 3개 계층으로 구성 (API, 엔진, 연산 처리)
- 엔진에서는 다차원 텐서 및 자동 미분 처리
- 연산 처리층에서는 텐서에 대한 연산 처리

torch: GPU를 지원하는 텐서 패키지
- 다차원 텐서를 기반으로 다양한 수학적 연산이 가능
- GPU에서도 연산 가능

torch.autograd: 자동 미분 패키지
- tensorflow 등 다른 프레임워크 대비 차별화
- 즉시 계산 가능

torch.nn: 신경망 구축 및 훈련 패키지
- 합성곱 신경망, 순환 신경망, 정규화 등이 포함되어 신경망 구축이 편리

torch.multiprocessing: 파이썬 멀티프로세싱 패키지
- 프로세스 전반에 걸쳐 텐서의 메모리 공유가 가능
- 서로 다른 프로세스에서 동일한 데이터(텐서)에 대한 접근 및 사용이 가능

torch.utils: DataLoader 및 기타 유틸리티를 제공하는 패키지
- 모델에 데이터를 제공하기 위한 torch.utils.data.DataLoader 모듈을 주로 상요
- 병목 현상을 디버깅하기 위한 torch.utils.bottleneck
- 모델 혹은 모델의 일부를 검사하기 위한 torch.utils.checkpoint 등

#### 오프셋과 스트라이드

A(2×3)와 AT(3×2)는 다른 형태(shape)를 갖지만 스토리지의 값들은 서로 같음
A랑 AT를 구분하기위해 오프셋과 스트라이드 사용


#### 텐서 다루기

텐서 생성
```python
import torch
print(torch.tensor([[1, 2], [3, 4]])) # 2차원 형태의 텐서
print(torch.tensor([[1, 2]], device="cuda:0")) # GPU에 텐서 설정
print(torch.tensor([[1, 2]], dtype=torch.float64)) # dtype을 이용하여 텐서 설정
```
* cuda:0는 GPU

tensor를 numpy ndarray로 변환하기
```python
# tensor를 numpy의 ndarray로 변환하기
temp = torch.tensor([[1, 2], [3, 4]])
tmp_np = temp.numpy()

# GPU로 텐서 만들기
temp = torch.tensor([1, 2], [3, 4], device="cuda:0")
print(temp.to("cpu").numpy())
```

TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.

GPU 텐서일 경우 바로 ndarray 변환이 안되기 때문에 CPU로 이동시킨 후 numpy() 로 변환 가능

#### 텐서의 차원 조작

* 텐서의 차원을 변경하는 방법은 view
* view는 numpy의 reshape와 유사하고, cat은 다른 길이의 텐서를 하나로 병합할 때 사용(concat)
* transpose는 행렬의 전치나 차원의 순서를 변경할 때 사용


```python
data = pd.read_csv('./data/class2.csv')

x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()
y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()
```
- unsqueeze 차원 늘리기 squeeze 차원 축소

##### 텐서 차원 변경
```python
print(temp.view(4, 1)) # 4x1로 변경
print(temp.view(-1)) # 1차원 벡터로 변경
print(temp.view(1, -1)) # -1은 (1,?)의 ?를 자동 계산해서 처리
# 결론은 1x4로 바뀌게 됨
```

##### 클래스

```python
class CustomDataset(Dataset):
    # 필요한 변수를 선언하고, 데이터셋의 전처리를 하는 함수
    def __init__(self, csv_file):
        self.label = pd.read_csv(csv_file)
    
    # 데이터셋의 길이, 즉 총 샘플의 수를 가져오는 함수
    def __len__(self):
        return len(self.label)
    
    # 데이터셋에서 특정 데이터를 가져오는 함수(index 번째 데이터를 반환하는 함수이며, 이때 반환되는 값은 텐서 형태)
    def __getitem__(self, idx):
        sample = torch.tensor(self.label.iloc[idx, 0:3]).int()
        label = torch.tensor(self.label.iloc[idx, 3]).int()
        return sample, label
    

tensor_dataset = CustomDataset('./data/covtype.csv')
dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)
```

- DataLoader는 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용
- 데이터는 미리 잘려있지 않고 내부에 iterator에 포함된 index를 이용하여 배치 크기만큼 반환함

```python
for i, data in enumerate(dataset, 0):
    print(i, end=' ')
    batch = data[0]
    print(batch.size())
```
* dataset은 iterable
* enumerate(iterable한 객체, index값)

batch_size가 4이기 때문에 한 번에 torch.Size([4, 3])으로 들어옴
(3개 feature의 column으로 4개의 row씩)


https://pytorch.org/vision/0.8/datasets.html


