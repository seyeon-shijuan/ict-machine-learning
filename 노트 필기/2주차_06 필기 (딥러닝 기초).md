
#### 모델의 정의
딥러닝 모델 설정은 model이라는 함수를 선언하며 시작
model = Sequential()로 시작되는 부분은 딥러닝의 구조를 짜고 층을 설정하는 부분
이어서 나오는 model.compile() 은 앞에서 정한 모델을 컴퓨터가 이해하게끔 변환
model.fit()은 모델 수행

```python
model = Sequential()
model.add(Dense(30, input_dim=16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
```

- Dense = fully connected layer, 각 입력 노드가 모든 출력 노드에 연결되어 있음
- Dense(출력 뉴런수, 입력층, 활성화 함수)
- **sigmoid = 이진분류로 마지막에 사용** (치역이 0~1)

노드란 가중합에 해당하는 것으로, 이전층에서 전달된 변수와 가중치, 바이어스가 하나로 모이게 되는 곳
input_dim: 입력 데이터에서 몇 개의 값을 가져올 지 정하는 것 -> 시작할때 feature 개수
Dense(30, 16)이라면 16개의 값을 받아서 30개로 내보내는 것

#### 모델 컴파일
앞서 지정한 모델이 효과적으로 구현되도록 여러 환경 설정하여 컴파일하는 부분
1. 어떤 오차함수를 사용할지 설정
- 선형 회귀에서 사용한 평균 제곱 오차 (평균 제곱 오차, 평균 절대 오차, 평균 절대 백분율 오차, 평균 제곱 로그 오차)
- 로지스틱 회귀에서 사용한 교차 엔트로피 오차 (binary_crossentropy, category_crossentropy)

```python
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
```

2. 옵티마이저 선택
- adam이 가장 많이 사용하는 최적화 함수
- back propagation 해주는 함수

#### 모델 실행하기
컴파일 환경을 주어진 데이터를 불러서 실행하는 것

```python
history = model.fit(X, y, epochs=5, batch_size=16)
```

- 학습 프로세스가 모든 샘프레 대해 한 번 실행되는 것을 1 epoch라고 함
- epoch = 5 각 샘플이 처음부터 끝까지 다섯 번 재사용 될때까지 실행 반복
- batch_size = 16 16개씩 끊어서 처리
- 배치가 너무 크면 학습 속도가 느려지고 너무 작으면 실행 값의 편차가 생겨서 전체 결괏값이 불안정
- 메모리 성능에 맞는 batch_size로 설정



#### 데이터 조사

**데이터간 상관관계를 확인하는 이유**

>계수 추정의 불안정성: 다중공선성으로 인해 독립 변수 간에 상관관계가 높을 경우, 모델이 해당 변수들의 영향을 정확히 추정하기 어려워집니다. 계수의 변동성이 커지며, 예측력이 떨어질 수 있습니다.
>
>계수의 부호 변화: 다중공선성 때문에 독립 변수들 간의 상관관계가 높으면 계수의 부호가 예측과 반대로 나올 수 있습니다. 이는 의미 없는 결과를 나타낼 수 있습니다.
>
>모델 해석의 어려움: 다중공선성이 있는 모델은 어떤 독립 변수가 종속 변수에 어떤 영향을 미치는지 명확하게 파악하기 어렵습니다. 변수들 간에 상호작용이 복잡해질 수 있습니다.


- corr 확인하기
가장 아래에있는 diabetes 줄을 보면 됨
-> 가장 높은변수 plasma

![[Pasted image 20230808124332.png]]


#### 모델 설명

```python
model = Sequential()
model.add(Dense(12, input_dim=8, activation='relu', name='Dense_1'))
model.add(Dense(8, activation='relu', name='Dense_2'))
model.add(Dense(1, activation='sigmoid', name='Dense_3'))
model.summary()
```

1. dense_1: 8차원 입력 12차원 출력되는 시작 레이어, activation은 relu로 0~1로 출력됨
   입력층과 첫 번째 은닉층을 연결해 주는 1층
2. dense_3: sigmoid함수가 있는 마지막 출력층

- 층의 뉴런 한개는 퍼셉트론이라고 부름
- Dense는 fully connected layer
- bias는 뉴런의 개수와 같음 (뉴런 1개당 bias는 1개씩 있음 y = ax +b니까)
- 첫 번째 층의 경우 입력 값 8개가 층 안에서 12개의 노드로 분산되므로 가중치가 8×12 = 96개가 되고, 각 노드에 바이어스가 한 개씩 있으니 전체 파라미터 수는 96 + 12 = 108이 됨



sigmoid = 이진분류 마지막 레이어
softmax =  다항분류 마지막 레이어(전체 확률의 합은 1)