{"cells":[{"cell_type":"markdown","id":"e2dae951","metadata":{"id":"e2dae951"},"source":["\n","\n","자연어 처리(NLP)란\n","\n","한국어와 영어 등 우리가 평소 쓰는 말을 자연어 라고 한다.\n","\n","자연어 처리는 (Natural Language Processing)를 풀어서 말하면\n","우리의 말을 컴퓨터에게 이해 시키기 위한 기술(분야)이다.\n","\n","자연어 처리가 추구하는 목표는 사람의 말을 부드럽게 컴퓨터가 이해하도록 만들어서,\n","컴퓨터가 우리에게 도움이 되는 일을 수행하게 하는 것이다.\n","\n","우리의 말은 문자로 구성되며 말의 의미는 '단어'로 구성된다.\n","\n","단어는 의미의 최소단위이기 때문에 자연어를 컴퓨터에게 이해시키는 데 단어의 의미를\n","이해시키는 것이 중요하다.\n","\n","[세가지 기법]\n",". 시소러스를 활용한 기법\n",". 통계기반 기법\n",". 추론(예측)기반 기법(word2vec) => 신경망\n","\n","\n","\n"]},{"cell_type":"markdown","id":"aa0db3e9","metadata":{"id":"aa0db3e9"},"source":["[시소리스]\n","\n","동의어의 예: \"car\",\"auto\",\"automobile\"등은 \"자동차\"를 뜻한다.\n","\n","    car = auto automobile machine motocar\n","\n","단어들의 의미의 상/하 관계에 기초 해 그래프로 표현한다.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"a3df5a5f","metadata":{"id":"a3df5a5f"},"source":["시소러스의 문제점\n","\n","WordNet과 같은 시소러스에는 수많은 단어에 대한 동의어와 게층구조 등의\n","관계가 정의 되어 있다.\n","그리고 이 지식을 이용하면 '단어의 의미'를 컴퓨터에 전달할 수 있다.\n","하지만 사람이 수작업으로 레이블링하는 방식에는 문제들이 존재\n","\n","1. 시대변화에 대응하기 어렵다.\n","신조어 혹은 의미 변화된 단어들을 바로 적용하기 어렵다.\n","\n","2. 사람을 쓰는 비용이 발생\n","현존하는 영어 단어의 수는 1,000만개가 넘으며 WordNet에 등록 된 단어는 20만개이상\n","\n","3. 단어의 미묘한 차이를 표현할 수 없다.\n","예를 들어 빈티지와 레트로의 의미는 같으나 용법의 차이가 존해\n","\n","위 문제를 피하기 위해 '통계 기반 기법' 과 신경망을 사용한 '추론 기반 기법'을 사용\n"]},{"cell_type":"markdown","id":"f4c2f258","metadata":{"id":"f4c2f258"},"source":["\n","[단어의 분산 표현]\n","색에는 고유한 이름이 붙여진 다채로운 색들도 있고.\n","RGB라는 세가지 성분이 어떤 비율로 섞여 있느냐로 표현하는 방법\n","전자는 색의 가짓수만큼의 이름을 부여하는 반면에 후자는 색을 3차원의 벡터로 표현\n","\n","여기서 부목할 점은 RGB같은 벡터 표현이 단 3개의 성분으로 간결하게\n","표현할 수 있고 색을 더 정확하게 명시할 수 있다는 점이다.\n","\n","색을 벡터로 표현하듯 단어도 벡터로 표현할 수 있다.\n","이를 단어의 분산표현이라고 한다.\n","\n","\n","분포가설: 통계기반 기법\n","분포가설이란 단어의 의미는 주변 단어에 의해 형성 된다는 것이다.\n","분포가설이 말하고자 하는 것은 단어 자체에는 의미가 없고\n","그 단어가 사용된 맥락이 의미를 형성한다는 것이다.\n","\n","예를 들어 I drink beer를 iguzzle beer라고 해도 guzzle를 drink로\n","이해할 수 있다는 것이다.\n","위도우 크기가 2인 맥락의 예 단어 \"goodbye\"에 주목한다면\n","그 좌우의 두 단어(총 네단어)를 맥락으로 이용한다.\n","\n","you say goodbye and i say hello.\n","\n","위 그림의 goodbye를 기준으로 좌우의 두 단어씩이 맥락에 해당한다.\n","맥락의 크기를 윈도우 크기라고 한다. 여기서는 위도우 크기가 2억이기 때문에\n","좌우로 두 단어씩이 맥락에 포함된다.\n","\n"]},{"cell_type":"markdown","id":"872ab235","metadata":{"id":"872ab235"},"source":["동시 발생 행렬   : 통계 기반 기법\n","\n","분포 가설에 기초해 단어를 벡터로 나타내는 방법을 생각해 보면\n","주변 단어를 세어보는 방법이 떠오른다.  ==> 이를 통 계기 반기법이라고 함\n","\n","단어 \"you\" 의 맥락을 세어본다.\n","\n","\n","you say goodbye and i say hello.\n","\n","\n","단어가 총 7개이며 윈도우 크기는 1로 하고 단어 ID가 0dls 'you'로 부터\n","단어의 맥락에 해당하는 단어의 빈도를 세어보자\n","'you'의 맥락은 'say'라는 단어 하나뿐이다.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"b447f08b","metadata":{"id":"b447f08b"},"source":["통계 기반 기법의 문제점\n","\n","통계 기반 기법과 추론 기법 비교\n","\n","\n","통계기반 기법(배치 학습)     추론기반 기법(미니 배치 학습)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","통계기반 기법은 학습 데이터를 한꺼번에 처리한다.\n","배치 학습 추론기반 기법은 학습 데이터의 일부를 사용하여 순차적으로 학습\n","\n","미니배치학습:\n","말뭉치의 어휘 수가 많아 SVD등 계산량이 큰 작업 처리\n","어려운 경우에도 신경망을 학습 시킬 수 있다는 의미\n","데이터를 작게 나눠 학습하기 때문\n","\n","\n"]},{"cell_type":"markdown","id":"df0c80d1","metadata":{"id":"df0c80d1"},"source":["추론 기반 기법 개요\n","\n","모델 관점에서 보면, 추론 문제는 다음과 같다\n","\n","추론기반기법: 맥락을 입력하면 모델은 각 단어의 출현확률을 출력한다.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    추론 기반 기법에는 어떠한 모델이 등장\n","\n","    우리는 이 모델로 신경망을 사용\n","    모델은 맥락 정보를 입력 받아 출현 할 수 있는 각 단어의 출현확률을 출력\n","    이러한 틀 안에서 말뭉치를 사용해 모델이 올바른 추측을 내 놓도록 학습\n","    그 학습의 결과로 단어의 분산 표현을 얻는 것이 추론 기반 기법의 전체그림\n","\n"]},{"cell_type":"markdown","id":"0450b4bc","metadata":{"id":"0450b4bc"},"source":["신경망에서의 단어 처리\n","지금부터 신경망을 이용하여 단어를 처리해 보자.\n","단어를 있는 그대로 처리할 수 없으니 고정 질이의 벡터로 변환해야한다.\n","이때 사용하는 대표적인 방법이 단어를 원 핫 표현으로 변환해야 한다.\n","워 핫 표현이란.\n","벡터의 원소 중 하나만 1이고 나머지는 모두 0인 벡터를 만한다.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","단어를 원 핫 표현으로 변환하는 방법\n",". 먼저 총 어휘 수 만큼의 원소를 갖는 벡터를 준비하고\n","인덱스가 단어 ID 와 같은 원소를 1로, 나머지는 모두 0으로 설정한다.\n","이처럼 단어를 고정 길이 벡터로 변환하면 신경망이 입력층은 뉴런 수를\n","고정 할 수 있다."]},{"cell_type":"markdown","id":"a0dd9213","metadata":{"id":"a0dd9213"},"source":["Embedding 계층\n","\n","\n","Embedding이란, 텍스트를 구성하는 하나의 단어를 수치화하는 방법의 일종이다.\n","텍스트분석에서 흔히 사용하는 방식은 단어 하나에 인덱스 정수를 할당하는\n","Bag of Words방법이다.\n","이 방법을 사용하면 문서는 단어장에 있는 단어의 갯수와 같은 크기의 벡터가 되고\n","단어장의 각 단어가 그 문서에 나온 횟수만큼 벡터의 인덱스 위치의 숫자를 증가\n","단어장이 \"I\",\"am\",\"boy\",\"girl\" 다섯개의 단어로 이루어진 경우 각 단어에 다음과\n","같은 숫자를 할당\n","\n","I : 0\n","am : 1\n","a : 2\n","boy : 3\n","girl: 4\n","\n","이때 I am a girl 이라는 무서는 다음과 같은 벡터로 만들 수 있다.\n","\n","[1,1,1,0,1]\n","\n","\n","단어 임베딩은 하나의 단어를 하나의 인덱스 정수가 아니라 실수 벡터로 나타낸다\n","예를 들어 2차원 임베딩 => 숫자 벡터가 될수 있다.\n","\n","I : (0.3,0.2)\n","am : (0.1,0.8)\n","a : (0.5,0.6)\n","...\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"6a1f633c","metadata":{"id":"6a1f633c"},"source":["[Word Embedding]\n","\n","단어를 밀집 벡터(dense vector)의 형태로 표현하는 방법을 워드 임베딩\n","이 밀집 벡터를 워드 임베딩 과정을 통해 나온 결과라고 하여 임베딩 벡터라고 함\n","\n","\n","-                원-핫 벡터                임베딩 벡터\n","\n","차원         고차원(단어 집합 크기)           저차원\n","\n","다른 표현    희소 벡터 일종                   밀집 벡터 일종\n","\n","표현 방법    수동                             훈련데이터로부터 학습함\n","\n","값의 타입    1과 0                             실수\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"130c33bb","metadata":{"id":"130c33bb"},"source":["# h1\n","\n","[텍스트 전처리]\n","\n","토큰화(Tokenization)\n","\n","Tokenization이란 text를 여러 개의 Token으로 나누는 것을 말함\n","\n","보통 공백, 구두점, 특수문자 등으로 이를 나누는데 그 방법이 다양한\n","Tokenizer가 있다.\n","\n","\n","[케라스 Tokenizer]\n","\n","tf.keras.preprocessing.text.Tokenizer(\n","    num_words = None,\n","    filters = '! \"#$()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n","    lower=True, split=' ',char_level=False, oov_token=None,\n","    document_count=0, **kwargs\n","\n",")\n","\n","\n","자연어 처리의 전처리 단계: 토큰화, 단어 집합 생성, 정수 인코딩, 패딩\n","\n",".Tokenizer 정의\n","\n","tokenizer = Tokenizer(num_woeds=vocab_size, oov_token=oov_tok)\n","\n","num_words: 단어 집합 max 사이즈를 지정, 가장 빈도수가 높은 단어만 사용\n","\n","oov_token: 단어 집합에 없는 단어를 어떻게 표기할 것인지 지정\n","\n","\n",".패딩: padding\n","\n","training_padded = pad_sequences(training_sequences, maxlen=max_length,\n","                               padding=padding_type, truncating=trunc_type)\n","\n","maxlen: 최대 문장 길이를 정의. 최대 문장 길이보다 길면, 자른다.\n","\n","truncation : 문장의 길이가 maxlen보다 길 때 앞을 자를 지 뒤를 자를 지 정의\n","\n","padding: 문장의 길이가 maxlen보다 짧을 때 채워 줄 값을 앞을 채울 지 정의\n"]},{"cell_type":"code","execution_count":null,"id":"90b7056f","metadata":{},"outputs":[],"source":["tk = Tokenizer(num_)"]},{"cell_type":"code","execution_count":1,"id":"bdbab529","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['I love my dog', 'I love my cat']\n"]}],"source":["sentence = [\"I love my dog\", \"I love my cat\"]\n","print(sentence)"]},{"cell_type":"code","execution_count":null,"id":"8771c6ff","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
