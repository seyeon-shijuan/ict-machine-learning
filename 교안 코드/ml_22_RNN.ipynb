{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8PmIE6aDoPL",
        "outputId": "6ee5fd17-0672-4723-c52e-ea043e041335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "sIMHr-t9EAeT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "TEXT = torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "LABEL = torchtext.data.Field(sequential=False)"
      ],
      "metadata": {
        "id": "PqJQALPIEyKT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "train_data, test_data = IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "id": "N5ZZcr9mE0oz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "for example in train_data.examples:\n",
        "  text = [x.lower() for x in vars(example)['text']]\n",
        "  text = [x.replace(\"<br>\",\"\") for x in text]\n",
        "  text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "  text = [s for s in text if s]\n",
        "  vars(example)['text'] = text"
      ],
      "metadata": {
        "id": "NwMq0GRqE3Tz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(0), split_ratio=0.8)"
      ],
      "metadata": {
        "id": "WKF7VX1zE6TL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnx8s1SyE89D",
        "outputId": "4987aca1-7fd2-4ed2-eff4-3e541620ce17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVNqjbW2E-P7",
        "outputId": "28c2d520-e0d7-4a22-a545-a1311bbcd1a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 10002\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZHZyE5RE_cz",
        "outputId": "632f9782-4017-485d-9e05-7d2be93ded7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7c34d8aff1f0>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embeding_dim = 100\n",
        "hidden_size = 300\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "metadata": {
        "id": "X--FtpH0FO2i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9_hzkh0FQ6y",
        "outputId": "944d55da-2546-48d0-d9cd-4bd5436627b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size):\n",
        "        super(RNNCell_Encoder, self).__init__()\n",
        "        self.rnn = nn.RNNCell(input_dim, hidden_size)\n",
        "\n",
        "    def forward(self, inputs): #------ inputs는 입력 시퀀스로 (시퀀스 길이, 배치, 임베딩(seq,batch, embedding))의 형태를 갖습니다.\n",
        "        bz = inputs.shape[1] #------ 배치를 가져옵니다.\n",
        "        ht = torch.zeros((bz, hidden_size)).to(device)# ------ 배치와 은닉층 뉴런의 크기를 0으로 초기화\n",
        "        for word in inputs:\n",
        "            ht = self.rnn(word, ht) #------ ②\n",
        "        return ht\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.em = nn.Embedding(len(TEXT.vocab.stoi), embeding_dim) #------ ③\n",
        "        self.rnn = RNNCell_Encoder(embeding_dim, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.em(x)\n",
        "        x = self.rnn(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9U6z4v2FVTC",
        "outputId": "dcf7263a-df2a-4163-e894-795984ac4ce5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (em): Embedding(10002, 100)\n",
              "  (rnn): RNNCell_Encoder(\n",
              "    (rnn): RNNCell(100, 300)\n",
              "  )\n",
              "  (fc1): Linear(in_features=300, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "M33Q8GUpFZuS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(epoch, model, trainloader, validloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for b in trainloader:\n",
        "        x, y = b.text, b.label\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += (y_pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    valid_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in validloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            valid_correct += (y_pred == y).sum().item()\n",
        "            valid_total += y.size(0)\n",
        "            valid_running_loss += loss.item()\n",
        "\n",
        "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    epoch_valid_acc = valid_correct / valid_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'loss： ', round(epoch_loss, 3),\n",
        "          'accuracy:', round(epoch_acc, 3),\n",
        "          'valid_loss： ', round(epoch_valid_loss, 3),\n",
        "          'valid_accuracy:', round(epoch_valid_acc, 3)\n",
        "          )\n",
        "    return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc\n"
      ],
      "metadata": {
        "id": "_IIIXuk4Fb4C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch,model,train_iterator,valid_iterator)\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    valid_acc.append(epoch_valid_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdIQLtKzFd8y",
        "outputId": "fd2dfabb-b8f3-4880-becc-f3a955444204"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss：  0.012 accuracy: 0.483 valid_loss：  0.011 valid_accuracy: 0.503\n",
            "epoch:  1 loss：  0.011 accuracy: 0.504 valid_loss：  0.011 valid_accuracy: 0.498\n",
            "epoch:  2 loss：  0.011 accuracy: 0.508 valid_loss：  0.011 valid_accuracy: 0.497\n",
            "epoch:  3 loss：  0.011 accuracy: 0.515 valid_loss：  0.011 valid_accuracy: 0.497\n",
            "epoch:  4 loss：  0.011 accuracy: 0.523 valid_loss：  0.011 valid_accuracy: 0.51\n",
            "286.07288122177124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(epoch, model, testloader):\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    test_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in testloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            test_correct += (y_pred == y).sum().item()\n",
        "            test_total += y.size(0)\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
        "    epoch_test_acc = test_correct / test_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'test_loss： ', round(epoch_test_loss, 3),\n",
        "          'test_accuracy:', round(epoch_test_acc, 3)\n",
        "          )\n",
        "    return epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "SjBD_r-OFfh7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_test_loss, epoch_test_acc = evaluate(epoch,\n",
        "                                               model,\n",
        "                                               test_iterator)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "    test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHu5w_ilGPpe",
        "outputId": "739f1e6e-18ca-4dd7-8e96-2d08a3bf38d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss：  0.011 test_accuracy: 0.499\n",
            "epoch:  1 test_loss：  0.011 test_accuracy: 0.499\n",
            "epoch:  2 test_loss：  0.011 test_accuracy: 0.499\n",
            "epoch:  3 test_loss：  0.011 test_accuracy: 0.499\n",
            "epoch:  4 test_loss：  0.011 test_accuracy: 0.499\n",
            "544.6764152050018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential = True, batch_first = True, lower = True)\n",
        "LABEL = torchtext.data.Field(sequential = False, batch_first = True)\n",
        "# TEXT = torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "# LABEL = torchtext.data.Field(sequential=False)\n",
        "\n",
        "# from torchtext.legacy import datasets\n",
        "from torchtext.datasets import IMDB\n",
        "\n",
        "train_data, test_data = IMDB.splits(TEXT, LABEL)\n",
        "# train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(split_ratio = 0.8)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TevwsVx8Nxn-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "wN_h67b4GvOi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2"
      ],
      "metadata": {
        "id": "o1u4GE8KOT0v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicRNN(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p = 0.2):\n",
        "        super(BasicRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        h_0 = self._init_state(batch_size = x.size(0))\n",
        "        x, _ = self.rnn(x, h_0)\n",
        "        h_t = x[:, -1, :]\n",
        "        self.dropout(h_t)\n",
        "        logit = torch.sigmoid(self.out(h_t))\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size = 1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "QA0bRTeYSRC9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicRNN(n_layers = 1, hidden_dim = 256, n_vocab = vocab_size, embed_dim = 128, n_classes = n_classes, dropout_p = 0.5)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "W4yhHhvsSbrT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if b % 50 == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(e,\n",
        "                                                                           b * len(x),\n",
        "                                                                           len(train_iter.dataset),\n",
        "                                                                           100. * b / len(train_iter),\n",
        "                                                                           loss.item()))"
      ],
      "metadata": {
        "id": "IfoxoEDkSOXw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    model.eval()\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction = \"sum\")\n",
        "        total += y.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "Rbqpg3XYS0Lv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    train(model, optimizer, train_iterator)\n",
        "    val_loss, val_accuracy = evaluate(model, valid_iterator)\n",
        "    print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss, val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ErqVJ3V46u",
        "outputId": "6b4cd1c7-a111-4186-e569-1c9c9239bf65"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.686724\n",
            "Train Epoch: 1 [5000/20000 (25%)]\tLoss: 0.693827\n",
            "Train Epoch: 1 [10000/20000 (50%)]\tLoss: 0.692457\n",
            "Train Epoch: 1 [15000/20000 (75%)]\tLoss: 0.698273\n",
            "[EPOCH: 1], Validation Loss:  0.69 | Validation Accuracy:  0.51\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.695002\n",
            "Train Epoch: 2 [5000/20000 (25%)]\tLoss: 0.693549\n",
            "Train Epoch: 2 [10000/20000 (50%)]\tLoss: 0.692079\n",
            "Train Epoch: 2 [15000/20000 (75%)]\tLoss: 0.697341\n",
            "[EPOCH: 2], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.694642\n",
            "Train Epoch: 3 [5000/20000 (25%)]\tLoss: 0.692655\n",
            "Train Epoch: 3 [10000/20000 (50%)]\tLoss: 0.694853\n",
            "Train Epoch: 3 [15000/20000 (75%)]\tLoss: 0.692699\n",
            "[EPOCH: 3], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.690801\n",
            "Train Epoch: 4 [5000/20000 (25%)]\tLoss: 0.692195\n",
            "Train Epoch: 4 [10000/20000 (50%)]\tLoss: 0.694356\n",
            "Train Epoch: 4 [15000/20000 (75%)]\tLoss: 0.695268\n",
            "[EPOCH: 4], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.693272\n",
            "Train Epoch: 5 [5000/20000 (25%)]\tLoss: 0.692764\n",
            "Train Epoch: 5 [10000/20000 (50%)]\tLoss: 0.691845\n",
            "Train Epoch: 5 [15000/20000 (75%)]\tLoss: 0.688912\n",
            "[EPOCH: 5], Validation Loss:  0.69 | Validation Accuracy:  0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_iterator)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzE8LuvEYERG",
        "outputId": "7c8ea6da-7af9-4219-feb2-04f0822d7acc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.68 | Test Accuracy:  0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cn7Z2esYgyzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}